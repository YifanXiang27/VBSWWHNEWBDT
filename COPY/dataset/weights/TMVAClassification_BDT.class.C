// Class: ReadBDT
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : BDT::BDT
TMVA Release   : 4.2.1         [262657]
ROOT Release   : 6.24/04       [399364]
Creator        : yxiang
Date           : Thu Jun 30 11:59:35 2022
Host           : Darwin HMBRW-A-001-M1-002.local 20.5.0 Darwin Kernel Version 20.5.0: Sat May 8 05:10:31 PDT 2021; root:xnu-7195.121.3~9/RELEASE_ARM64_T8101 arm64
Dir            : /Users/yxiang/Analysis/result/22_06_25/Sig_bkg_BDT/MD4Tr30Purity95
Training events: 28874
Analysis type  : [Classification]


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
V: "False" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
H: "False" [Print method-specific help message]
NTrees: "30" [Number of trees in the forest]
MaxDepth: "4" [Max depth of the decision tree allowed]
nCuts: "-1" [Number of grid points in variable range used in finding optimal cut in node splitting]
BoostType: "AdaBoost" [Boosting type for the trees in the forest (note: AdaCost is still experimental)]
NodePurityLimit: "9.500000e-01" [In boosting/pruning, nodes with purity > NodePurityLimit are signal; background otherwise.]
SeparationType: "crossentropy" [Separation criterion for node splitting]
# Default:
VerbosityLevel: "Default" [Verbosity level]
VarTransform: "None" [List of variable transformations performed before training, e.g., "D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)"]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]
MinNodeSize: "5%" [Minimum percentage of training events required in a leaf node (default: Classification: 5%, Regression: 0.2%)]
AdaBoostR2Loss: "quadratic" [Type of Loss function in AdaBoostR2]
UseBaggedBoost: "False" [Use only a random subsample of all events for growing the trees in each boost iteration.]
Shrinkage: "1.000000e+00" [Learning rate for BoostType=Grad algorithm]
AdaBoostBeta: "5.000000e-01" [Learning rate  for AdaBoost algorithm]
UseRandomisedTrees: "False" [Determine at each node splitting the cut variable only as the best out of a random subset of variables (like in RandomForests)]
UseNvars: "3" [Size of the subset of variables used with RandomisedTree option]
UsePoissonNvars: "True" [Interpret "UseNvars" not as fixed number but as mean of a Poisson distribution in each split with RandomisedTree option]
BaggedSampleFraction: "6.000000e-01" [Relative size of bagged event sample to original size of the data sample (used whenever bagging is used (i.e. UseBaggedBoost, Bagging,)]
UseYesNoLeaf: "False" [Use Sig or Bkg categories, or the purity=S/(S+B) as classification of the leaf node -> Real-AdaBoost]
NegWeightTreatment: "inverseboostnegweights" [How to treat events with negative weights in the BDT training (particular the boosting) : IgnoreInTraining;  Boost With inverse boostweight; Pair events with negative and positive weights in training sample and *annihilate* them (experimental!)]
Css: "1.000000e+00" [AdaCost: cost of true signal selected signal]
Cts_sb: "1.000000e+00" [AdaCost: cost of true signal selected bkg]
Ctb_ss: "1.000000e+00" [AdaCost: cost of true bkg    selected signal]
Cbb: "1.000000e+00" [AdaCost: cost of true bkg    selected bkg ]
RegressionLossFunctionBDTG: "huber" [Loss function for BDTG regression.]
HuberQuantile: "7.000000e-01" [In the Huber loss function this is the quantile that separates the core from the tails in the residuals distribution.]
DoBoostMonitor: "False" [Create control plot with ROC integral vs tree number]
UseFisherCuts: "False" [Use multivariate splits using the Fisher criterion]
MinLinCorrForFisher: "8.000000e-01" [The minimum linear correlation between two variables demanded for use in Fisher criterion in node splitting]
UseExclusiveVars: "False" [Variables already used in fisher criterion are not anymore analysed individually for node splitting]
DoPreselection: "False" [and and apply automatic pre-selection for 100% efficient signal (bkg) cuts prior to training]
SigToBkgFraction: "1.000000e+00" [Sig to Bkg ratio used in Training (similar to NodePurityLimit, which cannot be used in real adaboost]
PruneMethod: "nopruning" [Note: for BDTs use small trees (e.g.MaxDepth=3) and NoPruning:  Pruning: Method used for pruning (removal) of statistically insignificant branches ]
PruneStrength: "0.000000e+00" [Pruning strength]
PruningValFraction: "5.000000e-01" [Fraction of events to use for optimizing automatic pruning.]
SkipNormalization: "False" [Skip normalization at initialization, to keep expectation value of BDT output according to the fraction of events]
nEventsMin: "0" [deprecated: Use MinNodeSize (in % of training events) instead]
UseBaggedGrad: "False" [deprecated: Use *UseBaggedBoost* instead:  Use only a random subsample of all events for growing the trees in each iteration.]
GradBaggingFraction: "6.000000e-01" [deprecated: Use *BaggedSampleFraction* instead: Defines the fraction of events to be used in each iteration, e.g. when UseBaggedGrad=kTRUE. ]
UseNTrainEvents: "0" [deprecated: Use *BaggedSampleFraction* instead: Number of randomly picked training events used in randomised (and bagged) trees]
NNodesMax: "0" [deprecated: Use MaxDepth instead to limit the tree size]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 6
Hbbscore                      Hbbscore                      Hbbscore                      Hbbscore                                                        'F'    [0.900390625,0.99951171875]
Hbbmass                       Hbbmass                       Hbbmass                       Hbbmass                                                         'F'    [51.71875,484.5]
Wjetscore                     Wjetscore                     Wjetscore                     Wjetscore                                                       'F'    [0.900390625,0.99951171875]
Wjetmass                      Wjetmass                      Wjetmass                      Wjetmass                                                        'F'    [50.125,504.75]
Wjettau2                      Wjettau2                      Wjettau2                      Wjettau2                                                        'F'    [0.00279998779297,0.391845703125]
trans_E                       trans_E                       trans_E                       trans_E                                                         'F'    [1000.02746582,3998.63232422]
NSpec 0


============================================================================ */

#include <array>
#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#include <algorithm>
#include <limits>

#define NN new BDTNode

#ifndef BDTNode__def
#define BDTNode__def

class BDTNode {

public:

   // constructor of an essentially "empty" node floating in space
   BDTNode ( BDTNode* left,BDTNode* right,
                          int selector, double cutValue, bool cutType, 
                          int nodeType, double purity, double response ) :
   fLeft         ( left         ),
   fRight        ( right        ),
   fSelector     ( selector     ),
   fCutValue     ( cutValue     ),
   fCutType      ( cutType      ),
   fNodeType     ( nodeType     ),
   fPurity       ( purity       ),
   fResponse     ( response     ){
   }

   virtual ~BDTNode();

   // test event if it descends the tree at this node to the right
   virtual bool GoesRight( const std::vector<double>& inputValues ) const;
   BDTNode* GetRight( void )  {return fRight; };

   // test event if it descends the tree at this node to the left 
   virtual bool GoesLeft ( const std::vector<double>& inputValues ) const;
   BDTNode* GetLeft( void ) { return fLeft; };   

   // return  S/(S+B) (purity) at this node (from  training)

   double GetPurity( void ) const { return fPurity; } 
   // return the node type
   int    GetNodeType( void ) const { return fNodeType; }
   double GetResponse(void) const {return fResponse;}

private:

   BDTNode*   fLeft;     // pointer to the left daughter node
   BDTNode*   fRight;    // pointer to the right daughter node
   int                     fSelector; // index of variable used in node selection (decision tree)   
   double                  fCutValue; // cut value applied on this node to discriminate bkg against sig
   bool                    fCutType;  // true: if event variable > cutValue ==> signal , false otherwise
   int                     fNodeType; // Type of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal 
   double                  fPurity;   // Purity of node from training
   double                  fResponse; // Regression response value of node
}; 

//_______________________________________________________________________
   BDTNode::~BDTNode()
{
   if (fLeft  != NULL) delete fLeft;
   if (fRight != NULL) delete fRight;
}; 

//_______________________________________________________________________
bool BDTNode::GoesRight( const std::vector<double>& inputValues ) const
{
   // test event if it descends the tree at this node to the right
   bool result;
     result = (inputValues[fSelector] >= fCutValue );
   if (fCutType == true) return result; //the cuts are selecting Signal ;
   else return !result;
}

//_______________________________________________________________________
bool BDTNode::GoesLeft( const std::vector<double>& inputValues ) const
{
   // test event if it descends the tree at this node to the left
   if (!this->GoesRight(inputValues)) return true;
   else return false;
}

#endif

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() : fStatusIsClean( true ) {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;

   // returns classifier status
   bool IsStatusClean() const { return fStatusIsClean; }

 protected:

   bool fStatusIsClean;
};

#endif

class ReadBDT : public IClassifierReader {

 public:

   // constructor
   ReadBDT( std::vector<std::string>& theInputVars )
      : IClassifierReader(),
        fClassName( "ReadBDT" ),
        fNvars( 6 )
   {
      // the training input variables
      const char* inputVars[] = { "Hbbscore", "Hbbmass", "Wjetscore", "Wjetmass", "Wjettau2", "trans_E" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 0;
      fVmin[1] = 0;
      fVmax[1] = 0;
      fVmin[2] = 0;
      fVmax[2] = 0;
      fVmin[3] = 0;
      fVmax[3] = 0;
      fVmin[4] = 0;
      fVmax[4] = 0;
      fVmin[5] = 0;
      fVmax[5] = 0;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadBDT() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const override;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   double fVmin[6];
   double fVmax[6];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[6];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)
   std::vector<BDTNode*> fForest;       // i.e. root nodes of decision trees
   std::vector<double>                fBoostWeights; // the weights applied in the individual boosts
};

double ReadBDT::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   double myMVA = 0;
   double norm  = 0;
   for (unsigned int itree=0; itree<fForest.size(); itree++){
      BDTNode *current = fForest[itree];
      while (current->GetNodeType() == 0) { //intermediate node
         if (current->GoesRight(inputValues)) current=(BDTNode*)current->GetRight();
         else current=(BDTNode*)current->GetLeft();
      }
      myMVA += fBoostWeights[itree] *  current->GetPurity();
      norm  += fBoostWeights[itree];
   }
   return myMVA /= norm;
}

void ReadBDT::Initialize()
{
  double inf = std::numeric_limits<double>::infinity();
  double nan = std::numeric_limits<double>::quiet_NaN();
  // itree = 0
  fBoostWeights.push_back(0.768760691041512);
  fForest.push_back( 
NN(
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.997168,-99) , 
NN(
0, 
0, 
-1, 0, 1, 1, 0.966892,-99) , 
3, 105.781, 1, 0, 0.990928,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.886558,-99) , 
2, 0.958252, 0, 0, 0.976256,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.944375,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.514408,-99) , 
5, 1924.6, 0, 0, 0.709469,-99) , 
0, 0.989502, 0, 0, 0.891005,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.837274,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.486039,-99) , 
2, 0.977783, 0, 0, 0.700101,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.263137,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.150757,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.0356111,-99) , 
2, 0.989014, 0, 0, 0.0621859,-99) , 
5, 1246.29, 0, 0, 0.108283,-99) , 
0, 0.994873, 0, 0, 0.216987,-99) , 
5, 1468.4, 0, 0, 0.5,-99)    );
  // itree = 1
  fBoostWeights.push_back(0.480131);
  fForest.push_back( 
NN(
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.998728,-99) , 
NN(
0, 
0, 
-1, 0, 1, 1, 0.980631,-99) , 
0, 0.99585, 0, 0, 0.995097,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.862889,-99) , 
4, 0.0448151, 1, 0, 0.956292,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.910486,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.523882,-99) , 
2, 0.990479, 0, 0, 0.701413,-99) , 
0, 0.989502, 0, 0, 0.859049,-99) , 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.810915,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.443706,-99) , 
5, 1199.35, 0, 0, 0.647605,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.210102,-99) , 
3, 104.844, 1, 0, 0.545956,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.407425,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.151179,-99) , 
5, 1208.35, 0, 0, 0.25135,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.0497551,-99) , 
1, 137.938, 1, 0, 0.181801,-99) , 
0, 0.977783, 0, 0, 0.363761,-99) , 
5, 1638.09, 0, 0, 0.508792,-99)    );
  // itree = 2
  fBoostWeights.push_back(0.323059);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.988792,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.863624,-99) , 
4, 0.0380402, 1, 0, 0.960577,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.929704,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.649592,-99) , 
0, 0.996338, 0, 0, 0.725941,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.383282,-99) , 
2, 0.974365, 0, 0, 0.614454,-99) , 
5, 2025.15, 0, 0, 0.693649,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.691166,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.506013,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.245936,-99) , 
5, 1300.98, 0, 0, 0.327352,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.039225,-99) , 
3, 140.938, 1, 0, 0.273205,-99) , 
0, 0.997314, 0, 0, 0.339504,-99) , 
4, 0.0545197, 1, 0, 0.508796,-99)    );
  // itree = 3
  fBoostWeights.push_back(0.266276);
  fForest.push_back( 
NN(
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.988938,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.886881,-99) , 
0, 0.991943, 0, 0, 0.946831,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.587949,-99) , 
3, 114.656, 1, 0, 0.874593,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.420359,-99) , 
1, 145.062, 1, 0, 0.791169,-99) , 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.675635,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.425302,-99) , 
5, 1287.81, 0, 0, 0.51975,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.113576,-99) , 
3, 121.969, 1, 0, 0.474025,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.115444,-99) , 
1, 148.812, 1, 0, 0.427513,-99) , 
5, 1693.69, 0, 0, 0.507615,-99)    );
  // itree = 4
  fBoostWeights.push_back(0.242003);
  fForest.push_back( 
NN(
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.971916,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.861248,-99) , 
4, 0.0354156, 1, 0, 0.912867,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.63587,-99) , 
0, 0.983154, 0, 0, 0.797297,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.660221,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.353015,-99) , 
3, 91.8438, 1, 0, 0.502729,-99) , 
5, 1283.87, 0, 0, 0.664706,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.754152,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.856309,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.360352,-99) , 
5, 1926.25, 0, 0, 0.389505,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.128996,-99) , 
1, 144.562, 1, 0, 0.335308,-99) , 
0, 0.998291, 0, 0, 0.388315,-99) , 
2, 0.986572, 0, 0, 0.506532,-99)    );
  // itree = 5
  fBoostWeights.push_back(0.169669);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.975319,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.857758,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.583316,-99) , 
5, 1689.93, 0, 0, 0.62221,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.274475,-99) , 
3, 114.656, 1, 0, 0.574671,-99) , 
5, 2276.4, 0, 0, 0.607997,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.540066,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.323236,-99) , 
3, 98.1562, 1, 0, 0.45619,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.227093,-99) , 
2, 0.970459, 0, 0, 0.360072,-99) , 
0, 0.975342, 0, 0, 0.505945,-99)    );
  // itree = 6
  fBoostWeights.push_back(0.171842);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.928201,-99) , 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.679246,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.447628,-99) , 
5, 1311.82, 0, 0, 0.542645,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.168111,-99) , 
1, 154.938, 1, 0, 0.507651,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.0774733,-99) , 
3, 150.812, 1, 0, 0.479323,-99) , 
5, 2276.4, 0, 0, 0.505273,-99)    );
  // itree = 7
  fBoostWeights.push_back(0.146211);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.956635,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.784643,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.561209,-99) , 
5, 1344.62, 0, 0, 0.65871,-99) , 
4, 0.0384369, 1, 0, 0.74237,-99) , 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.858396,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.550099,-99) , 
5, 1926.48, 0, 0, 0.581991,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.355276,-99) , 
4, 0.0779114, 1, 0, 0.525363,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.350253,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.18909,-99) , 
1, 132.312, 1, 0, 0.291463,-99) , 
2, 0.955322, 0, 0, 0.4568,-99) , 
0, 0.997803, 0, 0, 0.504411,-99)    );
  // itree = 8
  fBoostWeights.push_back(0.131343);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.850394,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.588426,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.366235,-99) , 
5, 1091.25, 0, 0, 0.533923,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.285138,-99) , 
1, 142.312, 1, 0, 0.495252,-99) , 
5, 1926.5, 0, 0, 0.528191,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.12572,-99) , 
3, 150.812, 1, 0, 0.504016,-99)    );
  // itree = 9
  fBoostWeights.push_back(0.119544);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.82476,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.820194,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.59335,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.404327,-99) , 
2, 0.96167, 0, 0, 0.526292,-99) , 
0, 0.999268, 0, 0, 0.556993,-99) , 
4, 0.0347748, 1, 0, 0.604515,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.585075,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.409631,-99) , 
3, 95.2188, 1, 0, 0.506206,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.421396,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.226724,-99) , 
1, 120.656, 1, 0, 0.314014,-99) , 
2, 0.980225, 0, 0, 0.410358,-99) , 
0, 0.984619, 0, 0, 0.50352,-99)    );
  // itree = 10
  fBoostWeights.push_back(0.128993);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.965035,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.883684,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.608857,-99) , 
5, 2294.25, 0, 0, 0.676611,-99) , 
0, 0.997803, 0, 0, 0.751239,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.597675,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.406324,-99) , 
5, 1106.73, 0, 0, 0.545265,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.473848,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.262506,-99) , 
1, 121.469, 1, 0, 0.373037,-99) , 
0, 0.968506, 0, 0, 0.483792,-99) , 
5, 1731.84, 0, 0, 0.522981,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.13119,-99) , 
3, 157.062, 1, 0, 0.503179,-99)    );
  // itree = 11
  fBoostWeights.push_back(0.117977);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.841318,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.66569,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.455471,-99) , 
2, 0.962158, 0, 0, 0.593808,-99) , 
0, 0.997803, 0, 0, 0.643783,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.622205,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.474071,-99) , 
2, 0.991455, 0, 0, 0.528368,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.409276,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.251541,-99) , 
5, 1136.94, 0, 0, 0.337058,-99) , 
3, 97.0312, 1, 0, 0.456498,-99) , 
5, 1379.54, 0, 0, 0.525185,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.177448,-99) , 
1, 162.812, 1, 0, 0.502845,-99)    );
  // itree = 12
  fBoostWeights.push_back(0.0848204);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.821547,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.693718,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.502065,-99) , 
3, 84.1562, 1, 0, 0.538906,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.357909,-99) , 
2, 0.945068, 0, 0, 0.500177,-99) , 
5, 2025.15, 0, 0, 0.521462,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.170749,-99) , 
3, 150.812, 1, 0, 0.502543,-99)    );
  // itree = 13
  fBoostWeights.push_back(0.109193);
  fForest.push_back( 
NN(
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.911256,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.645463,-99) , 
0, 0.997803, 0, 0, 0.697318,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.943215,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.445204,-99) , 
4, 0.0280075, 1, 0, 0.487652,-99) , 
3, 104.969, 1, 0, 0.628761,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.571469,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.415175,-99) , 
1, 127.219, 1, 0, 0.521997,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.426463,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.274154,-99) , 
5, 1136.94, 0, 0, 0.357297,-99) , 
3, 97.2188, 1, 0, 0.461809,-99) , 
5, 1379.54, 0, 0, 0.522389,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.196713,-99) , 
1, 162.938, 1, 0, 0.502352,-99)    );
  // itree = 14
  fBoostWeights.push_back(0.0843982);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.763064,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.648229,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.472506,-99) , 
3, 91.5312, 1, 0, 0.553978,-99) , 
5, 1537.05, 0, 0, 0.609011,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.837294,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.893418,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.442404,-99) , 
5, 2260.78, 0, 0, 0.452964,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.173323,-99) , 
3, 140.938, 1, 0, 0.431592,-99) , 
0, 0.999268, 0, 0, 0.448106,-99) , 
2, 0.991455, 0, 0, 0.502156,-99)    );
  // itree = 15
  fBoostWeights.push_back(0.0745966);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.736895,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.671956,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.532994,-99) , 
5, 1250.87, 0, 0, 0.589107,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.424535,-99) , 
2, 0.954834, 0, 0, 0.543909,-99) , 
5, 1689.93, 0, 0, 0.577036,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.60322,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.520627,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.366983,-99) , 
5, 1364.23, 0, 0, 0.422135,-99) , 
3, 88.3438, 1, 0, 0.471672,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.294681,-99) , 
1, 137.812, 1, 0, 0.42888,-99) , 
0, 0.983154, 0, 0, 0.502016,-99)    );
  // itree = 16
  fBoostWeights.push_back(0.0736691);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.87665,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.656984,-99) , 
5, 1637.69, 0, 0, 0.712355,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.571033,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.410482,-99) , 
2, 0.955322, 0, 0, 0.525895,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.362711,-99) , 
5, 1091.4, 0, 0, 0.489022,-99) , 
0, 0.998291, 0, 0, 0.516959,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.182198,-99) , 
3, 157.062, 1, 0, 0.501879,-99)    );
  // itree = 17
  fBoostWeights.push_back(0.0692609);
  fForest.push_back( 
NN(
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.738043,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.537027,-99) , 
0, 0.997803, 0, 0, 0.568695,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.277364,-99) , 
3, 140.938, 1, 0, 0.55083,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.36336,-99) , 
5, 1065.75, 0, 0, 0.519307,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.222834,-99) , 
1, 162.938, 1, 0, 0.501751,-99)    );
  // itree = 18
  fBoostWeights.push_back(0.0772999);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.831948,-99) , 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.805466,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.550346,-99) , 
5, 1689.9, 0, 0, 0.570814,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.540596,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.341237,-99) , 
2, 0.989014, 0, 0, 0.414251,-99) , 
1, 133.812, 1, 0, 0.529848,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.484575,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.333379,-99) , 
0, 0.976807, 0, 0, 0.413896,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.194907,-99) , 
3, 150.812, 1, 0, 0.37531,-99) , 
3, 102.844, 1, 0, 0.48874,-99) , 
5, 2276.4, 0, 0, 0.501631,-99)    );
  // itree = 19
  fBoostWeights.push_back(0.065371);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.774879,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.544698,-99) , 
3, 103.844, 1, 0, 0.67426,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.632498,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.490184,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.324839,-99) , 
5, 1067.54, 0, 0, 0.458306,-99) , 
3, 84.1562, 1, 0, 0.491241,-99) , 
5, 1693.69, 0, 0, 0.517725,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.246677,-99) , 
1, 162.438, 1, 0, 0.501519,-99)    );
  // itree = 20
  fBoostWeights.push_back(0.057385);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.876429,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.602185,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.462592,-99) , 
2, 0.96167, 0, 0, 0.557635,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.388286,-99) , 
5, 1065.74, 0, 0, 0.529794,-99) , 
5, 2294.37, 0, 0, 0.543102,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.483821,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.318208,-99) , 
1, 120.656, 1, 0, 0.402623,-99) , 
0, 0.962646, 0, 0, 0.501428,-99)    );
  // itree = 21
  fBoostWeights.push_back(0.0572566);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.813268,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.76605,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.561001,-99) , 
3, 83.7188, 1, 0, 0.592441,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.494054,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.342545,-99) , 
0, 0.940674, 0, 0, 0.465624,-99) , 
2, 0.992432, 0, 0, 0.507479,-99) , 
0, 0.999268, 0, 0, 0.521762,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.310199,-99) , 
4, 0.116791, 1, 0, 0.501356,-99)    );
  // itree = 22
  fBoostWeights.push_back(0.0560474);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.757472,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.538435,-99) , 
3, 103.844, 1, 0, 0.66047,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.617913,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.489908,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.338028,-99) , 
5, 1067.62, 0, 0, 0.460899,-99) , 
3, 84.5312, 1, 0, 0.492056,-99) , 
5, 1693.69, 0, 0, 0.516084,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.25479,-99) , 
1, 162.938, 1, 0, 0.501289,-99)    );
  // itree = 23
  fBoostWeights.push_back(0.0544852);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.836747,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.760647,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.603407,-99) , 
2, 0.991455, 0, 0, 0.662968,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.576943,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.444549,-99) , 
0, 0.98999, 0, 0, 0.493094,-99) , 
3, 83.7188, 1, 0, 0.521308,-99) , 
5, 2294.29, 0, 0, 0.532848,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.438879,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.316965,-99) , 
1, 125.594, 1, 0, 0.383676,-99) , 
2, 0.945068, 0, 0, 0.501222,-99)    );
  // itree = 24
  fBoostWeights.push_back(0.0560638);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.745846,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.662857,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.502698,-99) , 
3, 84.5312, 1, 0, 0.534906,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.465109,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.289116,-99) , 
5, 1174.72, 0, 0, 0.40403,-99) , 
1, 133.062, 1, 0, 0.499584,-99) , 
5, 2025.15, 0, 0, 0.513444,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.22172,-99) , 
3, 157.062, 1, 0, 0.501167,-99)    );
  // itree = 25
  fBoostWeights.push_back(0.0530405);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.761662,-99) , 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.692495,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.516385,-99) , 
2, 0.998291, 0, 0, 0.538397,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.470766,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.300368,-99) , 
1, 127.281, 1, 0, 0.415269,-99) , 
5, 1136.99, 0, 0, 0.501294,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.228745,-99) , 
3, 150.812, 1, 0, 0.488523,-99) , 
0, 0.999268, 0, 0, 0.501103,-99)    );
  // itree = 26
  fBoostWeights.push_back(0.0561623);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.755535,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.604243,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.456174,-99) , 
2, 0.96167, 0, 0, 0.5518,-99) , 
0, 0.997803, 0, 0, 0.585233,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.584915,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.463612,-99) , 
5, 1108.65, 0, 0, 0.537821,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.473576,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.328799,-99) , 
2, 0.968506, 0, 0, 0.4215,-99) , 
0, 0.987549, 0, 0, 0.47211,-99) , 
5, 1356.81, 0, 0, 0.514805,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.267769,-99) , 
1, 162.938, 1, 0, 0.501046,-99)    );
  // itree = 27
  fBoostWeights.push_back(0.0433367);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.781813,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.701155,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.54893,-99) , 
5, 1504.51, 0, 0, 0.590248,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.762767,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.466309,-99) , 
5, 2276.32, 0, 0, 0.474171,-99) , 
2, 0.994385, 0, 0, 0.506674,-99) , 
0, 0.999268, 0, 0, 0.518878,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.330485,-99) , 
4, 0.116791, 1, 0, 0.50099,-99)    );
  // itree = 28
  fBoostWeights.push_back(0.0456966);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.88539,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.581806,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.397184,-99) , 
3, 115.406, 1, 0, 0.55989,-99) , 
5, 2446.71, 0, 0, 0.569663,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.573508,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.528646,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.382112,-99) , 
2, 0.995361, 0, 0, 0.419216,-99) , 
1, 104.156, 1, 0, 0.45924,-99) , 
0, 0.975342, 0, 0, 0.524073,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.371536,-99) , 
2, 0.934326, 0, 0, 0.500954,-99)    );
  // itree = 29
  fBoostWeights.push_back(0.0468144);
  fForest.push_back( 
NN(
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.936889,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.630871,-99) , 
0, 0.998779, 0, 0, 0.672667,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -1, 0.607551,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.478749,-99) , 
3, 84.1562, 1, 0, 0.503692,-99) , 
5, 1693.69, 0, 0, 0.525611,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.271465,-99) , 
3, 150.812, 1, 0, 0.513948,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.285319,-99) , 
1, 162.438, 1, 0, 0.500914,-99)    );
   return;
};

// Clean up
inline void ReadBDT::Clear() 
{
   for (unsigned int itree=0; itree<fForest.size(); itree++) { 
      delete fForest[itree]; 
   }
}

inline double ReadBDT::GetMvaValue( const std::vector<double>& inputValues ) const
{
   // classifier response value
   double retval = 0;

   // classifier response, sanity check first
   if (!IsStatusClean()) {
      std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                << " because status is dirty" << std::endl;
   }
   else {
         retval = GetMvaValue__( inputValues );
   }

   return retval;
}
